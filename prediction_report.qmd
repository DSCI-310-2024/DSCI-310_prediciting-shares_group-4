---
title: Exploratory Data Analysis
jupyter: ir
---

### Introduction:

Social media platforms, such as Twitter, have transformed the way in which information is disseminated and consumed on a global scale. These digital arenas enable a vast online community to quickly share and consume personal thoughts and professional insights, threaded through a variety of media forms. With over 500 million active users, Twitter has become particularly noteworthy for pinpointing the workings of information exchange and the features of content that make it most popular (López-Goñi & Sánchez-Angulo, 2018).

In their research on user activity in Twitter, Oh and Syn (2015) posit that human behavior in everyday life is driven by many factors, and is thus complex and multi-faceted. They uncover a useful lens for examining user activity in casual online environments, while Luo et al.(2020) report that mobile technology which will exceed 12.3 billion devices by 2022, over 90% of which will be smartphones is increasingly prevalent. This underscores the increasing relevance of social media platforms in the everyday sharing and transmission of information.

This research is fundamentally concerned with discerning the determinants of article popularity, as captured by the number of times each article was shared, to bring to light the many factors that drive user engagement and content diffusion. Using a massive dataset of articles and associated measures over a period of two years from Mashable to build models that could more accurately identify the traits that result in the visibility and engagement of content published to social media. By exploring the relationship between shared articles' characteristics and how popular they become, the hope is that this work may yield findings that offer guidance to both enterprise and solo publishers seeking to make their work more prevalent and persuasive in the digital enclave.


```{r}
#| vscode: {languageId: r}
# Assuming your kernel autoinstalled renv, uncomment the following code
# to install the rest of the packages
# renv::restore()
```

```{r}
#| vscode: {languageId: r}
library(renv)
library(GGally)
library(tidymodels)
library(tidyverse)
library(leaps)
library(caret)
library(boot)
library(pROC)
library(repr)
library(glmnet)
```

```{r}
#| vscode: {languageId: r}
articles <- read_csv('data/OnlineNewsPopularity.csv')
```



```{r}
#| vscode: {languageId: r}
ggplot(data = articles) +
    geom_boxplot(aes(y = shares)) +
    labs(title = "Boxplot of Shares") +
    ylab(label = 'Shares') +
    theme(axis.title = element_text(size = 20), axis.text = element_text(size = 15), title = element_text(size = 25))
```

```{r}
#| vscode: {languageId: r}
summary(articles$shares)
sd(articles$shares)
```

The target variable is centered at 1400, while the spread is quite large, with a standard deviation of 11627. Therefore, we will adjust our work from regression to classification to determine whether an article will be popular. Our definition of an article being popular would to be above average, so an article will be classified as popular if its above 1400 shares, and will not be popular if below 1400.

```{r}
#| vscode: {languageId: r}
articles_temp <- articles

drop_columns <- c('url')

articles_temp <- articles_temp[, !(names(articles_temp) %in% c(drop_columns))]#, one_hot_columns))]

articles_temp <- articles_temp |> mutate('shares' = ifelse(shares >= 1400, 1 , 0))

articles_clean <- articles_temp
```

```{r}
#| vscode: {languageId: r}
write.csv(articles_clean, 'data/clean_Articles.csv')
```


```{r}
#| vscode: {languageId: r}
set.seed(2024)

articles_clean$ID <- 1:nrow(articles_clean)

training_articles <- articles_clean |> slice_sample(prop = 0.7)

testing_articles <- anti_join(articles_clean, training_articles, by = "ID")


training_articles <- training_articles[, !(names(training_articles) %in% c('ID'))]
testing_articles <- testing_articles[, !(names(testing_articles) %in% c('ID'))]

head(training_articles, 3)
nrow(training_articles)

head(testing_articles, 3)
nrow(testing_articles)
```

```{r}
#| vscode: {languageId: r}
write.csv(training_articles, 'data/training_data.csv')
write.csv(testing_articles, 'data/testing_data.csv')
```

Going to fit an initial linear model using all attributes to receive a baseline ordinary model for logistic regression. Using logistic regression since our target variable is a classification problem, and not a regression problem.

```{r}
#| vscode: {languageId: r}
article_logistic_regression <- glm(shares ~ ., data = training_articles, family = binomial)

summary(article_logistic_regression)
```

```{r}
#| vscode: {languageId: r}
# Code adapted from UBC STAT 301 Lectures 12/13, Gabriela V. Cohen Freue 2022

misclassification_rate <- function(y, p.hat){
 y_hat <- round(p.hat, 0)
 error_rate <- sum(abs(y - y_hat) == 1) / length(y_hat)
 return(error_rate)
}

cv_logistic <-
 cv.glm(
 glmfit = article_logistic_regression,
 data = training_articles,
 K = 10,
 cost = misclassification_rate)

cv_logistic$delta[1]
```

Our training error is 0.346, which is large. The large training error could be due to multiple factors, such as the underlying distribution. Due to the amount of parameters, each case is likely to have an unique set of attribute values so it becomes more difficult for the model

```{r}
#| vscode: {languageId: r}
articles_pred_class <- 
    round(predict(article_logistic_regression, newdata = training_articles, type = 'response'), 0)

head(articles_pred_class)
```

```{r}
#| vscode: {languageId: r}
articles_conf_mat <- 
        confusionMatrix(
            data = as.factor(articles_pred_class),
            reference = as.factor(training_articles$shares)
        )

articles_conf_mat
```

### TODO
Using our ordinary model as well as the training data, we predict whether an article is popular or not. Then we use that along with the true values for the confusion matrix, which shows ...

```{r}
#| vscode: {languageId: r}
options(repr.plot.width = 8, repr.plot.height = 8)

ROC_full_log <- roc(
    response = training_articles$shares,
    predictor = predict(article_logistic_regression, type = 'response')
)

plot(ROC_full_log,
        print.auc = TRUE, col = 'blue', lwd = 3, lty = 2,
        main = 'ROC Curves for Article Dataset'
    )
```

```{r}
#| vscode: {languageId: r}
auc_tibble <- tibble(Model = 'Full Model', AUC = as.double(ROC_full_log$auc))
auc_tibble
```

The AUC for the model is 0.709, meaning that there is 70.9% chance that our model will be able to identify between a popular and unpopular article.

Since we have multiple attributes, we wish to find the most significant attributes that contribute the most to the amount of shares an article receives. We will do so using forward selection by way of the `tidymodels` package.

```{r}
#| vscode: {languageId: r}
model_mat_X_train <-
    model.matrix(object = article_logistic_regression, data = training_articles)[, -1]

model_mat_Y_train <-
    as.matrix(training_articles$shares, ncol = 1)
```

```{r}
#| vscode: {languageId: r}
articles_cv_lambda_lasso <- 
    cv.glmnet(
        x = model_mat_X_train, y = model_mat_Y_train,
        alpha = 1,
        family = 'binomial',
        type.measure = 'auc',
        nfolds = 5
    )
articles_cv_lambda_lasso
```

```{r}
#| vscode: {languageId: r}
articles_lambda_1se_AUC_LASSO <- round(articles_cv_lambda_lasso$lambda.1se, 4)
```

```{r}
#| vscode: {languageId: r}
articles_LASSO_1se_AUC <- glmnet(
 x = model_mat_X_train, y = model_mat_Y_train,
 alpha = 1,
 family = "binomial",
 lambda = articles_lambda_1se_AUC_LASSO
)

sum((coef(articles_LASSO_1se_AUC)[, 1] != 0) == TRUE)
```

```{r}
#| vscode: {languageId: r}
auc_tibble <- auc_tibble |> add_row(Model = 'lasso', AUC = articles_cv_lambda_lasso$cvm[articles_cv_lambda_lasso$index["1se",]])
```

```{r}
#| vscode: {languageId: r}
auc_tibble
```

The lasso model has slightly less area under the curve, however it uses 36 input variables instead of the 60 the full model uses, which is more efficient to compute.

### Reference:

- López-Goñi, I., & Sánchez-Angulo, M. (2018). Social networks as a tool for science communication and public engagement: Focus on twitter. FEMS Microbiology Letters, 365(2), 1. https://doi.org/10.1093/femsle/fnx246
- Luo, T., Freeman, C., & Stefaniak, J. (2020). “Like, comment, and share”—professional development through social media in higher education: A systematic review. Educational Technology Research and Development, 68(4), 1659-1683. https://doi.org/10.1007/s11423-020-09790-5
- Oh, S., & Syn, S. Y. (2015). Motivations for sharing information and social support in social media: A comparative analysis of facebook, twitter, delicious, YouTube, and flickr. Journal of the Association for Information Science and Technology, 66(10), 2045-2060. https://doi.org/10.1002/asi.23320